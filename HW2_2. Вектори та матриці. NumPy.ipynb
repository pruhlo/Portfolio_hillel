{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e9b3c3-f63f-4e77-965e-62b9af32ef49",
   "metadata": {},
   "source": [
    "# 1. Знайти в датасеті таргет та видалити цю колонку з датасету (видаляти за індексом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf253360-8a59-43e4-8af0-4e5d3fb12198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.1, 3.5, 1.4, 0.2, b'Iris-setosa') (4.9, 3. , 1.4, 0.2, b'Iris-setosa')\n",
      " (4.7, 3.2, 1.3, 0.2, b'Iris-setosa') (4.6, 3.1, 1.5, 0.2, b'Iris-setosa')\n",
      " (5. , 3.6, 1.4, 0.2, b'Iris-setosa')]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import List, Tuple\n",
    "\n",
    "def load_iris_data(url: str) -> NDArray[Tuple[float, float, float, float, bytes]]:\n",
    "    \"\"\"\n",
    "    Loads the Iris dataset from the specified URL.\n",
    "\n",
    "    This function downloads the Iris dataset from the given URL and loads it into a NumPy structured array.\n",
    "    The dataset consists of 150 samples, each with 4 features and a class label.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL from which to download the Iris dataset.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A structured array with the following fields:\n",
    "        - 'sepal_length': float64, the length of the sepal in centimeters.\n",
    "        - 'sepal_width': float64, the width of the sepal in centimeters.\n",
    "        - 'petal_length': float64, the length of the petal in centimeters.\n",
    "        - 'petal_width': float64, the width of the petal in centimeters.\n",
    "        - 'class': bytes, the class label (species) of the iris sample.\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    >>> iris_data = load_iris_data(url)\n",
    "    >>> print(iris_data[:5])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the data types for each column\n",
    "    dtype: List[Tuple[str, str]] = [\n",
    "        ('sepal_length', 'f8'),\n",
    "        ('sepal_width', 'f8'),\n",
    "        ('petal_length', 'f8'),\n",
    "        ('petal_width', 'f8'),\n",
    "        ('class', 'S15')\n",
    "    ]\n",
    "    \n",
    "    # Load data from URL\n",
    "    data: NDArray[Tuple[float, float, float, float, bytes]] = np.genfromtxt(url, delimiter=',', dtype=dtype, encoding='utf-8')\n",
    "    \n",
    "    return data\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data(url)\n",
    "\n",
    "# Print the first 5 rows of data for verification\n",
    "print(iris_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da09830c-1e62-4579-b3fe-6e126896fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.1, 3.5, 1.4, 0.2) (4.9, 3. , 1.4, 0.2) (4.7, 3.2, 1.3, 0.2)\n",
      " (4.6, 3.1, 1.5, 0.2) (5. , 3.6, 1.4, 0.2)]\n"
     ]
    }
   ],
   "source": [
    "def remove_target_column(data: NDArray[Tuple[float, float, float, float, bytes]]) -> NDArray[Tuple[float, float, float, float]]:\n",
    "    \"\"\"\n",
    "    Removes the target column from the Iris dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        A structured array containing the Iris dataset with the target column.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A structured array with the target column removed.\n",
    "    \"\"\"\n",
    "    # Define the new data types for the array without the 'class' column\n",
    "    new_dtype = [('sepal_length', 'f8'), ('sepal_width', 'f8'), ('petal_length', 'f8'), ('petal_width', 'f8')]\n",
    "    \n",
    "    # Create a new array with the target column removed\n",
    "    new_data = np.zeros(data.shape, dtype=new_dtype)\n",
    "    \n",
    "    for field in new_data.dtype.names:\n",
    "        new_data[field] = data[field]\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data(url)\n",
    "\n",
    "# Remove the target column\n",
    "iris_data_no_target = remove_target_column(iris_data)\n",
    "\n",
    "# Print the first 5 rows of data for verification\n",
    "print(iris_data_no_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519351ef-a9e4-4dee-89d9-e05cb82e06ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "def load_iris_data_without_target(url: str) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Loads the Iris dataset from the specified URL and removes the target column.\n",
    "\n",
    "    This function downloads the Iris dataset from the given URL, removes the target column,\n",
    "    and returns the data as a NumPy array with only the feature columns.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL from which to download the Iris dataset.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 2D array with the following columns:\n",
    "        - 'sepal_length': float64, the length of the sepal in centimeters.\n",
    "        - 'sepal_width': float64, the width of the sepal in centimeters.\n",
    "        - 'petal_length': float64, the length of the petal in centimeters.\n",
    "        - 'petal_width': float64, the width of the petal in centimeters.\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    >>> iris_data = load_iris_data_without_target(url)\n",
    "    >>> print(iris_data[:5])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data from URL, use 'U15' for the last column to handle the class labels as strings\n",
    "    data = np.genfromtxt(url, delimiter=',', dtype='f8, f8, f8, f8, U15', encoding='utf-8')\n",
    "    \n",
    "    # Extract the feature columns (all but the last column)\n",
    "    features = np.array([list(row)[:4] for row in data], dtype=np.float64)\n",
    "    \n",
    "    return features\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Print the first 5 rows of data for verification\n",
    "print(iris_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d334cfa5-e583-4be0-acb2-b65e6e7edbc8",
   "metadata": {},
   "source": [
    "# 2. Перетворити колонки, що залишились в 2D масив (або впевнитись, що це уже 2D масив)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793ba0e0-ab18-44f5-9b7f-dec4d8ae39cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting array is 2D\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "def load_iris_data_without_target(url: str) -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Loads the Iris dataset from the specified URL and removes the target column.\n",
    "\n",
    "    This function downloads the Iris dataset from the given URL, removes the target column,\n",
    "    and returns the data as a 2D NumPy array with only the feature columns.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL from which to download the Iris dataset.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        A 2D array with the following columns:\n",
    "        - 'sepal_length': float64, the length of the sepal in centimeters.\n",
    "        - 'sepal_width': float64, the width of the sepal in centimeters.\n",
    "        - 'petal_length': float64, the length of the petal in centimeters.\n",
    "        - 'petal_width': float64, the width of the petal in centimeters.\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    >>> url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    >>> iris_data = load_iris_data_without_target(url)\n",
    "    >>> print(iris_data[:5])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data from URL, use 'U15' for the last column to handle the class labels as strings\n",
    "    data = np.genfromtxt(url, delimiter=',', dtype='f8, f8, f8, f8, U15', encoding='utf-8')\n",
    "    \n",
    "    # Extract the feature columns (all but the last column) and ensure it's a 2D array\n",
    "    features = np.array([list(row)[:4] for row in data], dtype=np.float64)\n",
    "    \n",
    "    # Ensure the resulting array is 2D\n",
    "    if features.ndim != 2:\n",
    "        raise ValueError(\"The resulting array is not 2D\")\n",
    "    else:\n",
    "        print(\"The resulting array is 2D\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Print the first 5 rows of data for verification\n",
    "print(iris_data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b969e-51e4-4683-a0c9-e8a1a13148b9",
   "metadata": {},
   "source": [
    "# 3. Порахувати mean, median, standard deviation для 1-ї колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90701448-ceca-48c6-a862-0e14a54ea7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting array is 2D\n",
      "Mean: 5.843333333333334\n",
      "Median: 5.8\n",
      "Standard Deviation: 0.8253012917851409\n"
     ]
    }
   ],
   "source": [
    "def calculate_statistics(data: NDArray[np.float64], column_index: int) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates mean, median, and standard deviation for a specified column in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        A 2D array containing the dataset.\n",
    "    column_index : int\n",
    "        The index of the column for which to calculate the statistics.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Tuple[float, float, float]\n",
    "        A tuple containing the mean, median, and standard deviation of the specified column.\n",
    "    \"\"\"\n",
    "    column_data = data[:, column_index]\n",
    "    mean = np.mean(column_data)\n",
    "    median = np.median(column_data)\n",
    "    std_dev = np.std(column_data)\n",
    "    return mean, median, std_dev\n",
    "\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Calculate statistics for the first column (sepal_length)\n",
    "mean, median, std_dev = calculate_statistics(iris_data, 0)\n",
    "\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Median: {median}\")\n",
    "print(f\"Standard Deviation: {std_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe2d69-9e44-4cc7-b339-493f3d460f63",
   "metadata": {},
   "source": [
    "# 4. Вставити 20 значень np.nan на випадкові позиції в масиві (при використанні звичайного рандому можуть накластись позиції, тому знайти рішення, яке гарантує 20 унікальних позицій)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c69cb74-a6df-40c9-befb-907a3fdcb6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting array is 2D\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 nan 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 nan 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 nan 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 nan]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 nan 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [nan 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  nan 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 nan]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 nan 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 nan 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 nan 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 nan 4.4 1.2]\n",
      " [6.1 nan 4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 nan 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 nan 5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 nan]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [nan 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 nan]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 nan nan]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "def insert_nan_random_positions(array: np.ndarray, num_nans: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inserts np.nan at random unique positions in the given array.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    array : numpy.ndarray\n",
    "        The input array where np.nan values will be inserted.\n",
    "    num_nans : int\n",
    "        The number of np.nan values to insert.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The array with np.nan values inserted at random unique positions.\n",
    "    \"\"\"\n",
    "    # Determine unique random positions to insert np.nan\n",
    "    num_elements = array.size\n",
    "    random_indices = np.random.choice(num_elements, size=num_nans, replace=False)\n",
    "    \n",
    "    # Insert np.nan at selected positions\n",
    "    array.ravel()[random_indices] = np.nan\n",
    "    \n",
    "    return array\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Create a copy of the data to avoid modifying the original loaded data\n",
    "iris_data_copy = iris_data.copy()\n",
    "\n",
    "# Insert 20 np.nan values at random unique positions\n",
    "iris_data_nan = insert_nan_random_positions(iris_data_copy, num_nans=20)\n",
    "\n",
    "# Print the modified array to verify\n",
    "print(iris_data_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08430f8-420c-4955-9318-a9434a6ecf09",
   "metadata": {},
   "source": [
    "# 5. Знайти позиції вставлених значень np.nan в 1-й колонці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71cfe84f-d9d0-46d5-9d53-6579638db737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting array is 2D\n",
      "Positions of np.nan in the first column:\n",
      "[  1  21  26  39  52  67 102]\n"
     ]
    }
   ],
   "source": [
    "def find_nan_positions(array: np.ndarray, column_index: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Finds positions of np.nan values in the specified column of the array.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    array : numpy.ndarray\n",
    "        The input array where to find np.nan values.\n",
    "    column_index : int\n",
    "        The index of the column in which to search for np.nan values.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of indices where np.nan values are located in the specified column.\n",
    "    \"\"\"\n",
    "    column_data = array[:, column_index]\n",
    "    nan_positions = np.where(np.isnan(column_data))[0]\n",
    "    return nan_positions\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Create a copy of the data to avoid modifying the original loaded data\n",
    "iris_data_copy = iris_data.copy()\n",
    "\n",
    "# Insert 20 np.nan values at random unique positions\n",
    "iris_data_nan = insert_nan_random_positions(iris_data_copy, num_nans=20)\n",
    "\n",
    "# Find positions of np.nan in the first column (column index 0)\n",
    "nan_positions = find_nan_positions(iris_data_nan, column_index=0)\n",
    "\n",
    "print(\"Positions of np.nan in the first column:\")\n",
    "print(nan_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b5caa-b432-413d-be32-ab3e73bf77fa",
   "metadata": {},
   "source": [
    "# 6. Відфільтрувати массив за умовою: значення в 3-й колонці > 1.5 та значения в 1-й колонці < 5.0 (зберегти у іншу змінну)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54124dd2-fb40-4c3c-84fe-0a05080e005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting array is 2D\n",
      "Filtered data based on conditions:\n",
      "[[4.8 3.4 1.6 0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.7 nan 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [4.9 2.5 4.5 1.7]]\n"
     ]
    }
   ],
   "source": [
    "def filter_data(array: np.ndarray, threshold1: float, threshold2: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Filters the array based on conditions: values in the 3rd column > threshold1\n",
    "    and values in the 1st column < threshold2.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    array : numpy.ndarray\n",
    "        The input array to be filtered.\n",
    "    threshold1 : float\n",
    "        Threshold value for the 3rd column (petal_length).\n",
    "    threshold2 : float\n",
    "        Threshold value for the 1st column (sepal_length).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The filtered array based on the specified conditions.\n",
    "    \"\"\"\n",
    "    condition = (array[:, 2] > threshold1) & (array[:, 0] < threshold2)\n",
    "    filtered_array = array[condition]\n",
    "    return filtered_array\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_data = load_iris_data_without_target(url)\n",
    "\n",
    "# Create a copy of the data to avoid modifying the original loaded data\n",
    "iris_data_copy = iris_data.copy()\n",
    "\n",
    "# Insert 20 np.nan values at random unique positions\n",
    "iris_data_nan = insert_nan_random_positions(iris_data_copy, num_nans=20)\n",
    "\n",
    "# Define thresholds\n",
    "threshold_petal_length = 1.5\n",
    "threshold_sepal_length = 5.0\n",
    "\n",
    "# Filter the data\n",
    "filtered_data = filter_data(iris_data_nan, threshold_petal_length, threshold_sepal_length)\n",
    "\n",
    "# Print the filtered data\n",
    "print(\"Filtered data based on conditions:\")\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d0421-d63d-47ba-9ad9-4a76aa9885f8",
   "metadata": {},
   "source": [
    "# 7. Замінити всі значення np.nan на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e53574-8603-4dbe-807c-793acf3e4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data without NaNs replaced by 0:\n",
      "[[4.8 3.4 1.6 0.2]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.7 0.  1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [4.9 2.5 4.5 1.7]]\n"
     ]
    }
   ],
   "source": [
    "# Replace all np.nan values with 0\n",
    "filtered_data_no_nan = np.nan_to_num(filtered_data, nan=0)\n",
    "\n",
    "# Print the filtered data without NaNs replaced by 0\n",
    "print(\"Filtered data without NaNs replaced by 0:\")\n",
    "print(filtered_data_no_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e4ba6-44b5-42c6-888b-185a5161d3af",
   "metadata": {},
   "source": [
    "# 8. Порахувати всі унікальні значення в массиві та вивести їх разом із кількістю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff03690-2e97-40f2-816c-872c9c4cc58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and their counts:\n",
      "0.0: 1\n",
      "0.2: 4\n",
      "1.0: 1\n",
      "1.6: 3\n",
      "1.7: 1\n",
      "1.9: 1\n",
      "2.4: 1\n",
      "2.5: 1\n",
      "3.1: 1\n",
      "3.3: 1\n",
      "3.4: 2\n",
      "4.5: 1\n",
      "4.7: 1\n",
      "4.8: 3\n",
      "4.9: 2\n"
     ]
    }
   ],
   "source": [
    "# Find unique values and their counts\n",
    "unique_values, counts = np.unique(filtered_data_no_nan, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values and their counts:\")\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f3fd2-dede-49dd-ba15-9f9d6f37658c",
   "metadata": {},
   "source": [
    "# 9. Розбити масив по вертикалі на 2 рівні частини (не використовувати абсолютні числа, мають бути два массиви по 4 колонки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a728ad7b-f6bf-4888-ad04-4f07c6db7037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First half of the split array:\n",
      "[[4.8 3.4]\n",
      " [4.8 3.4]\n",
      " [4.7 0. ]\n",
      " [4.8 3.1]\n",
      " [4.9 2.4]\n",
      " [4.9 2.5]]\n",
      "\n",
      "Second half of the split array:\n",
      "[[1.6 0.2]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [3.3 1. ]\n",
      " [4.5 1.7]]\n"
     ]
    }
   ],
   "source": [
    "# Split the array vertically into two equal parts\n",
    "split_arrays = np.array_split(filtered_data_no_nan, 2, axis=1)\n",
    "\n",
    "# Print the two split arrays\n",
    "print(\"First half of the split array:\")\n",
    "print(split_arrays[0])\n",
    "print(\"\\nSecond half of the split array:\")\n",
    "print(split_arrays[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df8bc1-a107-4ae3-ab30-535c68edd777",
   "metadata": {},
   "source": [
    "# 10. Відсортувати обидва массиви по 1-й колонці: 1-й за збільшенням, 2-й за зменшенням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f7ff7a-465a-47a8-a2ee-811932f1deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted array 1 (ascending by the first column):\n",
      "[[4.7 0. ]\n",
      " [4.8 3.4]\n",
      " [4.8 3.4]\n",
      " [4.8 3.1]\n",
      " [4.9 2.4]\n",
      " [4.9 2.5]]\n",
      "\n",
      "Sorted array 2 (descending by the first column):\n",
      "[[4.5 1.7]\n",
      " [3.3 1. ]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Sort the first array (ascending order by the first column)\n",
    "sorted_array1 = split_arrays[0][np.argsort(split_arrays[0][:, 0])]\n",
    "\n",
    "# Sort the second array (descending order by the first column)\n",
    "sorted_array2 = split_arrays[1][np.argsort(-split_arrays[1][:, 0])]\n",
    "\n",
    "# Print the sorted arrays\n",
    "print(\"Sorted array 1 (ascending by the first column):\")\n",
    "print(sorted_array1)\n",
    "print(\"\\nSorted array 2 (descending by the first column):\")\n",
    "print(sorted_array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbcf0f-2399-49e9-90a7-d050fc08b722",
   "metadata": {},
   "source": [
    "# 11. Зібрати обидва массиви в одне ціле\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0350a5-9463-41a4-8623-a69a037945b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined array:\n",
      "[[4.7 0.  4.5 1.7]\n",
      " [4.8 3.4 3.3 1. ]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.9 2.4 1.6 0.2]\n",
      " [4.9 2.5 1.6 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two sorted arrays vertically (along columns)\n",
    "combined_array = np.concatenate((sorted_array1, sorted_array2), axis=1)\n",
    "\n",
    "# Print the combined array\n",
    "print(\"Combined array:\")\n",
    "print(combined_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e8c75-a66c-413c-a070-1ece0014a429",
   "metadata": {},
   "source": [
    "# 12. Знайти найбільш часто повторюване значення в массиві\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b7a901-17c3-445e-a554-20d7b994c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value: 0.2\n"
     ]
    }
   ],
   "source": [
    "def most_frequent_value(array: np.ndarray):\n",
    "    \"\"\"\n",
    "    Finds the most frequently occurring value in a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    array : numpy.ndarray\n",
    "        The input NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    object\n",
    "        The most frequently occurring value in the array.\n",
    "\n",
    "    Raises:\n",
    "    ------\n",
    "    ValueError\n",
    "        If the input array is empty or if there is a tie for the most frequent value.\n",
    "    \"\"\"\n",
    "    # Get unique values and their counts\n",
    "    unique_values, counts = np.unique(array, return_counts=True)\n",
    "    \n",
    "    # Find the index of the maximum count\n",
    "    max_count_index = np.argmax(counts)\n",
    "    \n",
    "    # Check if there is a tie for the most frequent value\n",
    "    if np.sum(counts == counts[max_count_index]) > 1:\n",
    "        raise ValueError(\"There is a tie for the most frequent value.\")\n",
    "    \n",
    "    # Return the most frequent value\n",
    "    most_frequent_value = unique_values[max_count_index]\n",
    "    return most_frequent_value\n",
    "\n",
    "# Find the most frequently occurring value\n",
    "try:\n",
    "    result = most_frequent_value(combined_array)\n",
    "    print(\"Most frequent value:\", result)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769f752-2689-4c59-a3fc-e7453182da5a",
   "metadata": {},
   "source": [
    "# 13. Написати функцію, яка б множила всі значення в колонці, які менше середнього значения в цій колонці, на 2, і ділила інші значення на 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4671802d-6718-4533-aa3b-0c96d9223b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(array: np.ndarray, column_index: int):\n",
    "    \"\"\"\n",
    "    Process a specific column in a NumPy array:\n",
    "    - Multiply values less than the column mean by 2.\n",
    "    - Divide other values by 4.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    array : numpy.ndarray\n",
    "        The input NumPy array.\n",
    "    column_index : int\n",
    "        Index of the column to process.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The processed array with modifications applied to the specified column.\n",
    "    \"\"\"\n",
    "    # Get the specified column\n",
    "    column = array[:, column_index]\n",
    "    \n",
    "    # Calculate the mean of the column\n",
    "    column_mean = np.mean(column)\n",
    "    \n",
    "    # Apply the transformations\n",
    "    column_processed = np.where(column < column_mean, column * 2, column / 4)\n",
    "    \n",
    "    # Replace the processed column back into the original array\n",
    "    processed_array = array.copy()\n",
    "    processed_array[:, column_index] = column_processed\n",
    "    \n",
    "    return processed_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ce8c9-ce6f-4ed9-a1bb-c7a9ab500b42",
   "metadata": {},
   "source": [
    "# 14. Застосувати отриману функцію до 3-ї колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1e0c541-1ae9-4f48-9172-8835c63a3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed columns:\n",
      "[[4.7   0.    1.125 1.7  ]\n",
      " [4.8   3.4   0.825 1.   ]\n",
      " [4.8   3.4   3.8   0.2  ]\n",
      " [4.8   3.1   3.2   0.2  ]\n",
      " [4.9   2.4   3.2   0.2  ]\n",
      " [4.9   2.5   3.2   0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "processed_column = process_column(combined_array, 2)\n",
    "print(\"\\nProcessed columns:\")\n",
    "print(processed_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a2cc8-936a-44ae-83dd-61ba0fa0f886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
